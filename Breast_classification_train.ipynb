{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",0)\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50844e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_list=['BRNT','BRID','BRIL','BRLC','BRDC']\n",
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':8,\n",
    "        'epochs':1000,\n",
    "        'n_classes':5,\n",
    "        'data_path':'../../data/NIPA/',\n",
    "        'inch':3,\n",
    "        }\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ ÏÖÄÏóê Ï∂îÍ∞ÄÌï¥ÏÑú ÌÖåÏä§Ìä∏Ìï¥Î≥¥ÏÑ∏Ïöî\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. BatchNorm ÏÉÅÌÉú ÌôïÏù∏\n",
    "def check_batchnorm_stats(model):\n",
    "    \"\"\"BatchNorm Î†àÏù¥Ïñ¥Ïùò running_meanÍ≥º running_var ÌôïÏù∏\"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            if torch.isnan(module.running_mean).any() or torch.isnan(module.running_var).any():\n",
    "                print(f\"NaN detected in {name}\")\n",
    "                print(f\"Running mean has NaN: {torch.isnan(module.running_mean).any()}\")\n",
    "                print(f\"Running var has NaN: {torch.isnan(module.running_var).any()}\")\n",
    "\n",
    "# 2. BatchNorm Ï¥àÍ∏∞Ìôî Ìï®Ïàò\n",
    "def reset_batchnorm_stats(model):\n",
    "    \"\"\"BatchNormÏùò running statistics Ï¥àÍ∏∞Ìôî\"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.reset_running_stats()\n",
    "\n",
    "# 3. ÏïàÏ†ÑÌïú eval Î™®Îìú ÏÑ§Ï†ï\n",
    "def safe_eval_mode(model):\n",
    "    \"\"\"ÏïàÏ†ÑÌïòÍ≤å eval Î™®ÎìúÎ°ú Ï†ÑÌôò\"\"\"\n",
    "    model.eval()\n",
    "    # BatchNorm Î†àÏù¥Ïñ¥Ïùò momentumÏùÑ ÏõêÎûòÎåÄÎ°ú Î≥µÍµ¨\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, 'backup_momentum'):\n",
    "            module.momentum = module.backup_momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,label):\n",
    "        \n",
    "        self.images = images\n",
    "        self.args=parmas\n",
    "        self.label=label\n",
    "        \n",
    "    def trans(self,image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "        label=self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "image_label=[]\n",
    "image_path=[]\n",
    "for i in tqdm(range(len(class_list))):\n",
    "    image_list=glob(params['data_path']+class_list[i]+'/*.jpeg')\n",
    "    for j in range(len(image_list)):\n",
    "        image_path.append(image_list[j])\n",
    "        image_label.append(i)\n",
    "        \n",
    "train_images=torch.zeros((len(image_path),params['inch'],params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(image_path))):\n",
    "    train_images[i]=trans(Image.open(image_path[i]).convert('RGB').resize((params['image_size'],params['image_size'])))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, image_label, test_size=0.2, random_state=42)\n",
    "# train_dataset=CustomDataset(params,X_train,F.one_hot(torch.tensor(y_train)).to(torch.int64))\n",
    "train_dataset=CustomDataset(params,train_images,F.one_hot(torch.tensor(image_label)).to(torch.int64))\n",
    "val_dataset=CustomDataset(params,X_test,F.one_hot(torch.tensor(y_test)).to(torch.int64))\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('tf_efficientnetv2_xl', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(custom_model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = custom_model(len(class_list),1280,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "base_optimizer = torch.optim.AdamW\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=params['lr'])\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_list)).to(device)\n",
    "model.load_state_dict(torch.load('../../model/NIPA_classification/Breast/modelEff_v2_XL_SAM_244.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6038747",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "sig=nn.Sigmoid()\n",
    "model_path='../../model/NIPA_classification/Breast/'\n",
    "create_dir(model_path)\n",
    "val_acc_list=[]\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        \n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        enable_running_stats(model)\n",
    "        optimizer.zero_grad()  # optimizer zero Î°ú Ï¥àÍ∏∞Ìôî\n",
    "        predict = model(x).to(device)\n",
    "        cost = F.cross_entropy(predict, y) # cost Íµ¨Ìï®\n",
    "        cost.backward() # costÏóê ÎåÄÌïú backward Íµ¨Ìï®\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        disable_running_stats(model)\n",
    "        predict = model(x).to(device)\n",
    "        cost1 = F.cross_entropy(predict, y) # cost Íµ¨Ìï®\n",
    "        cost1.backward() # costÏóê ÎåÄÌïú backward Íµ¨Ìï®\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        running_loss += cost.item()\n",
    "\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} loss : {running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "#validation\n",
    "    val=tqdm(val_dataloader)\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = F.cross_entropy(predict, y) # cost Íµ¨Ìï®\n",
    "            acc=accuracy(predict.argmax(dim=1),y.argmax(dim=1))\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{1000} Step: {count+1} loss : {val_running_loss/count:.4f}  accuracy: {acc_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "    if epoch%100==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='validation_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='validation_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), f'{model_path}modelEff_v2_XL_SAM_'+str(epoch)+'.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "torch.save(model.state_dict(), f'{model_path}modelEff_v2_XL_SAM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798615f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Performance Evaluation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "model_path='../../model/NIPA_classification/Breast/'\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, image_label, test_size=0.2, random_state=41)\n",
    "train_dataset=CustomDataset(params,X_train,F.one_hot(torch.tensor(y_train)).to(torch.int64))\n",
    "val_dataset=CustomDataset(params,X_test,F.one_hot(torch.tensor(y_test)).to(torch.int64))\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=1,shuffle=True)\n",
    "# Load the best model\n",
    "best_model_path = f'{model_path}modelEff_v2_XL_SAM_229.pt'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Test set evaluation\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "test_probabilities = []\n",
    "\n",
    "print(\"Evaluating on Test Set...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(val_dataloader, desc=\"Testing\"):\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        outputs = model(x)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        predictions = torch.argmax(probabilities, dim=1)\n",
    "        \n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_labels.extend(torch.argmax(y, dim=1).cpu().numpy())\n",
    "        test_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(test_labels, test_predictions, average=None)\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='macro')\n",
    "weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': class_list,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Test Set Performance Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Macro Average - Precision: {macro_precision:.4f}, Recall: {macro_recall:.4f}, F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted Average - Precision: {weighted_precision:.4f}, Recall: {weighted_recall:.4f}, F1-Score: {weighted_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìã Per-Class Performance:\")\n",
    "print(\"-\"*70)\n",
    "print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=class_list, columns=class_list)\n",
    "\n",
    "print(\"\\nüîÑ Confusion Matrix:\")\n",
    "print(\"-\"*30)\n",
    "print(cm_df.to_string())\n",
    "\n",
    "# Visualization with matplotlib only (avoiding seaborn compatibility issues)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Per-class metrics\n",
    "ax1 = axes[0]\n",
    "x_pos = np.arange(len(class_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax1.bar(x_pos - width, precision, width, label='Precision', alpha=0.8, color='skyblue')\n",
    "bars2 = ax1.bar(x_pos, recall, width, label='Recall', alpha=0.8, color='lightgreen')\n",
    "bars3 = ax1.bar(x_pos + width, f1, width, label='F1-Score', alpha=0.8, color='salmon')\n",
    "\n",
    "ax1.set_xlabel('Classes')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Per-Class Performance Metrics')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(class_list)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Subplot 2: Confusion Matrix Heatmap using matplotlib\n",
    "ax2 = axes[1]\n",
    "im = ax2.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "ax2.set_title('Confusion Matrix')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax2)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(class_list)):\n",
    "    for j in range(len(class_list)):\n",
    "        text = ax2.text(j, i, str(cm[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
    "\n",
    "ax2.set_xticks(range(len(class_list)))\n",
    "ax2.set_yticks(range(len(class_list)))\n",
    "ax2.set_xticklabels(class_list)\n",
    "ax2.set_yticklabels(class_list)\n",
    "\n",
    "# Subplot 3: Class Distribution\n",
    "ax3 = axes[2]\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "class_names = [class_list[i] for i in unique]\n",
    "colors = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen'][:len(class_names)]\n",
    "wedges, texts, autotexts = ax3.pie(counts, labels=class_names, autopct='%1.1f%%', \n",
    "                                   startangle=90, colors=colors)\n",
    "ax3.set_title('Test Set Class Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary for paper\n",
    "print(\"\\nüìù Summary for Paper:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"The stomach classification model achieved an overall accuracy of {accuracy:.4f} on the test set.\")\n",
    "print(f\"The macro-averaged F1-score was {macro_f1:.4f}, indicating {['poor', 'fair', 'good', 'excellent'][min(3, int(macro_f1*4))]} performance across all classes.\")\n",
    "\n",
    "# Individual class performance summary\n",
    "best_class = class_list[np.argmax(f1)]\n",
    "worst_class = class_list[np.argmin(f1)]\n",
    "print(f\"Best performing class: {best_class} (F1-Score: {f1[np.argmax(f1)]:.4f})\")\n",
    "print(f\"Most challenging class: {worst_class} (F1-Score: {f1[np.argmin(f1)]:.4f})\")\n",
    "\n",
    "# Export results to CSV for paper\n",
    "results_summary = {\n",
    "    'Metric': ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1-Score', \n",
    "               'Weighted Precision', 'Weighted Recall', 'Weighted F1-Score'],\n",
    "    'Value': [accuracy, macro_precision, macro_recall, macro_f1, \n",
    "              weighted_precision, weighted_recall, weighted_f1]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "results_df.to_csv(f'{model_path}per_class_results.csv', index=False)\n",
    "summary_df.to_csv(f'{model_path}overall_results.csv', index=False)\n",
    "cm_df.to_csv(f'{model_path}confusion_matrix.csv')\n",
    "\n",
    "print(f\"\\nüíæ Results saved to:\")\n",
    "print(f\"  - Per-class results: {model_path}per_class_results.csv\")\n",
    "print(f\"  - Overall results: {model_path}overall_results.csv\")\n",
    "print(f\"  - Confusion matrix: {model_path}confusion_matrix.csv\")\n",
    "\n",
    "# Additional statistics for paper\n",
    "print(f\"\\nüìà Additional Statistics:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Total test samples: {len(test_labels)}\")\n",
    "print(f\"Class distribution: {dict(zip(class_list, [support[i] for i in range(len(class_list))]))}\")\n",
    "print(f\"Standard deviation of F1-scores: {np.std(f1):.4f}\")\n",
    "print(f\"95% Confidence Interval for accuracy: [{accuracy - 1.96*np.sqrt(accuracy*(1-accuracy)/len(test_labels)):.4f}, {accuracy + 1.96*np.sqrt(accuracy*(1-accuracy)/len(test_labels)):.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
