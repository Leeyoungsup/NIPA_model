{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",0)\n",
    "print(f\"Device:\\t\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50844e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_list=['BRNT','BRID','BRIL','BRLC','BRDC']\n",
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':8,\n",
    "        'epochs':1000,\n",
    "        'n_classes':5,\n",
    "        'data_path':'../../data/NIPA/',\n",
    "        'inch':3,\n",
    "        }\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# 새로운 셀에 추가해서 테스트해보세요\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. BatchNorm 상태 확인\n",
    "def check_batchnorm_stats(model):\n",
    "    \"\"\"BatchNorm 레이어의 running_mean과 running_var 확인\"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            if torch.isnan(module.running_mean).any() or torch.isnan(module.running_var).any():\n",
    "                print(f\"NaN detected in {name}\")\n",
    "                print(f\"Running mean has NaN: {torch.isnan(module.running_mean).any()}\")\n",
    "                print(f\"Running var has NaN: {torch.isnan(module.running_var).any()}\")\n",
    "\n",
    "# 2. BatchNorm 초기화 함수\n",
    "def reset_batchnorm_stats(model):\n",
    "    \"\"\"BatchNorm의 running statistics 초기화\"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.reset_running_stats()\n",
    "\n",
    "# 3. 안전한 eval 모드 설정\n",
    "def safe_eval_mode(model):\n",
    "    \"\"\"안전하게 eval 모드로 전환\"\"\"\n",
    "    model.eval()\n",
    "    # BatchNorm 레이어의 momentum을 원래대로 복구\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, 'backup_momentum'):\n",
    "            module.momentum = module.backup_momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "    def __init__(self,parmas, images,label):\n",
    "        \n",
    "        self.images = images\n",
    "        self.args=parmas\n",
    "        self.label=label\n",
    "        \n",
    "    def trans(self,image):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "        label=self.label[index]\n",
    "        image = self.trans(image)\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "image_label=[]\n",
    "image_path=[]\n",
    "for i in tqdm(range(len(class_list))):\n",
    "    image_list=glob(params['data_path']+class_list[i]+'/*.jpeg')\n",
    "    for j in range(len(image_list)):\n",
    "        image_path.append(image_list[j])\n",
    "        image_label.append(i)\n",
    "        \n",
    "train_images=torch.zeros((len(image_path),params['inch'],params['image_size'],params['image_size']))\n",
    "for i in tqdm(range(len(image_path))):\n",
    "    train_images[i]=trans(Image.open(image_path[i]).convert('RGB').resize((params['image_size'],params['image_size'])))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, image_label, test_size=0.2, random_state=42)\n",
    "# train_dataset=CustomDataset(params,X_train,F.one_hot(torch.tensor(y_train)).to(torch.int64))\n",
    "train_dataset=CustomDataset(params,train_images,F.one_hot(torch.tensor(image_label)).to(torch.int64))\n",
    "val_dataset=CustomDataset(params,X_test,F.one_hot(torch.tensor(y_test)).to(torch.int64))\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('tf_efficientnetv2_xl', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(custom_model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = custom_model(len(class_list),1280,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "base_optimizer = torch.optim.AdamW\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=params['lr'])\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_list)).to(device)\n",
    "model.load_state_dict(torch.load('../../model/NIPA_classification/Breast/modelEff_v2_XL_SAM_244.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6038747",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "sig=nn.Sigmoid()\n",
    "model_path='../../model/NIPA_classification/Breast/'\n",
    "create_dir(model_path)\n",
    "val_acc_list=[]\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        \n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        enable_running_stats(model)\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = F.cross_entropy(predict, y) # cost 구함\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        disable_running_stats(model)\n",
    "        predict = model(x).to(device)\n",
    "        cost1 = F.cross_entropy(predict, y) # cost 구함\n",
    "        cost1.backward() # cost에 대한 backward 구함\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        running_loss += cost.item()\n",
    "\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} loss : {running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "#validation\n",
    "    val=tqdm(val_dataloader)\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = F.cross_entropy(predict, y) # cost 구함\n",
    "            acc=accuracy(predict.argmax(dim=1),y.argmax(dim=1))\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{1000} Step: {count+1} loss : {val_running_loss/count:.4f}  accuracy: {acc_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "    if epoch%100==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='validation_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='validation_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), f'{model_path}modelEff_v2_XL_SAM_'+str(epoch)+'.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "torch.save(model.state_dict(), f'{model_path}modelEff_v2_XL_SAM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798615f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Performance Evaluation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "model_path='../../model/NIPA_classification/Breast/'\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, image_label, test_size=0.2, random_state=41)\n",
    "train_dataset=CustomDataset(params,X_train,F.one_hot(torch.tensor(y_train)).to(torch.int64))\n",
    "val_dataset=CustomDataset(params,X_test,F.one_hot(torch.tensor(y_test)).to(torch.int64))\n",
    "dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=1,shuffle=True)\n",
    "# Load the best model\n",
    "best_model_path = f'{model_path}modelEff_v2_XL_SAM_229.pt'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Test set evaluation\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "test_probabilities = []\n",
    "\n",
    "print(\"Evaluating on Test Set...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(val_dataloader, desc=\"Testing\"):\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        outputs = model(x)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        predictions = torch.argmax(probabilities, dim=1)\n",
    "        \n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_labels.extend(torch.argmax(y, dim=1).cpu().numpy())\n",
    "        test_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "test_probabilities = np.array(test_probabilities)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(test_labels, test_predictions, average=None)\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='macro')\n",
    "weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': class_list,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\n📊 Test Set Performance Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Macro Average - Precision: {macro_precision:.4f}, Recall: {macro_recall:.4f}, F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted Average - Precision: {weighted_precision:.4f}, Recall: {weighted_recall:.4f}, F1-Score: {weighted_f1:.4f}\")\n",
    "\n",
    "print(\"\\n📋 Per-Class Performance:\")\n",
    "print(\"-\"*70)\n",
    "print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=class_list, columns=class_list)\n",
    "\n",
    "print(\"\\n🔄 Confusion Matrix:\")\n",
    "print(\"-\"*30)\n",
    "print(cm_df.to_string())\n",
    "\n",
    "# Visualization with matplotlib only (avoiding seaborn compatibility issues)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Per-class metrics\n",
    "ax1 = axes[0]\n",
    "x_pos = np.arange(len(class_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax1.bar(x_pos - width, precision, width, label='Precision', alpha=0.8, color='skyblue')\n",
    "bars2 = ax1.bar(x_pos, recall, width, label='Recall', alpha=0.8, color='lightgreen')\n",
    "bars3 = ax1.bar(x_pos + width, f1, width, label='F1-Score', alpha=0.8, color='salmon')\n",
    "\n",
    "ax1.set_xlabel('Classes')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Per-Class Performance Metrics')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(class_list)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Subplot 2: Confusion Matrix Heatmap using matplotlib\n",
    "ax2 = axes[1]\n",
    "im = ax2.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "ax2.set_title('Confusion Matrix')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax2)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(class_list)):\n",
    "    for j in range(len(class_list)):\n",
    "        text = ax2.text(j, i, str(cm[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
    "\n",
    "ax2.set_xticks(range(len(class_list)))\n",
    "ax2.set_yticks(range(len(class_list)))\n",
    "ax2.set_xticklabels(class_list)\n",
    "ax2.set_yticklabels(class_list)\n",
    "\n",
    "# Subplot 3: Class Distribution\n",
    "ax3 = axes[2]\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "class_names = [class_list[i] for i in unique]\n",
    "colors = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen'][:len(class_names)]\n",
    "wedges, texts, autotexts = ax3.pie(counts, labels=class_names, autopct='%1.1f%%', \n",
    "                                   startangle=90, colors=colors)\n",
    "ax3.set_title('Test Set Class Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary for paper\n",
    "print(\"\\n📝 Summary for Paper:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"The stomach classification model achieved an overall accuracy of {accuracy:.4f} on the test set.\")\n",
    "print(f\"The macro-averaged F1-score was {macro_f1:.4f}, indicating {['poor', 'fair', 'good', 'excellent'][min(3, int(macro_f1*4))]} performance across all classes.\")\n",
    "\n",
    "# Individual class performance summary\n",
    "best_class = class_list[np.argmax(f1)]\n",
    "worst_class = class_list[np.argmin(f1)]\n",
    "print(f\"Best performing class: {best_class} (F1-Score: {f1[np.argmax(f1)]:.4f})\")\n",
    "print(f\"Most challenging class: {worst_class} (F1-Score: {f1[np.argmin(f1)]:.4f})\")\n",
    "\n",
    "# Export results to CSV for paper\n",
    "results_summary = {\n",
    "    'Metric': ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1-Score', \n",
    "               'Weighted Precision', 'Weighted Recall', 'Weighted F1-Score'],\n",
    "    'Value': [accuracy, macro_precision, macro_recall, macro_f1, \n",
    "              weighted_precision, weighted_recall, weighted_f1]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "results_df.to_csv(f'{model_path}per_class_results.csv', index=False)\n",
    "summary_df.to_csv(f'{model_path}overall_results.csv', index=False)\n",
    "cm_df.to_csv(f'{model_path}confusion_matrix.csv')\n",
    "\n",
    "print(f\"\\n💾 Results saved to:\")\n",
    "print(f\"  - Per-class results: {model_path}per_class_results.csv\")\n",
    "print(f\"  - Overall results: {model_path}overall_results.csv\")\n",
    "print(f\"  - Confusion matrix: {model_path}confusion_matrix.csv\")\n",
    "\n",
    "# Additional statistics for paper\n",
    "print(f\"\\n📈 Additional Statistics:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Total test samples: {len(test_labels)}\")\n",
    "print(f\"Class distribution: {dict(zip(class_list, [support[i] for i in range(len(class_list))]))}\")\n",
    "print(f\"Standard deviation of F1-scores: {np.std(f1):.4f}\")\n",
    "print(f\"95% Confidence Interval for accuracy: [{accuracy - 1.96*np.sqrt(accuracy*(1-accuracy)/len(test_labels)):.4f}, {accuracy + 1.96*np.sqrt(accuracy*(1-accuracy)/len(test_labels)):.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
