{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "import cv2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=2\n",
    "img_size=1024\n",
    "class_list=[\n",
    "    \"Background\",\n",
    "    \"NT_stroma\",\n",
    "    \"NT_epithelial\",\n",
    "    \"NT_immune\",\n",
    "    \"Tumor\",\n",
    "    \"TP_invasive\",\n",
    "    \"TP_in_situ\",\n",
    "]\n",
    "tf = ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "    \n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='../../data/NIPA/breast/images/'\n",
    "img_list=glob(img_path+'*.jpeg')\n",
    "mask_list=[i.replace('/images/','/masks/') for i in img_list]\n",
    "mask_list=[i.replace('.jpeg','.npy') for i in mask_list]\n",
    "train_img_list,test_img_list,train_mask_list,test_mask_list=train_test_split(img_list,mask_list,test_size=0.2,random_state=41)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "        \n",
    "    def trans(self,image,label):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            label = transform(label)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path,label_path = self.img_path[idx],self.label[idx]\n",
    "        image = tf(Image.open(image_path))\n",
    "        label = torch.from_numpy(np.load(label_path)).float()\n",
    "        label=label.permute(2,0,1)\n",
    "        image,label = self.trans(image,label)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = CustomDataset(train_img_list, train_mask_list)\n",
    "\n",
    "test_dataset = CustomDataset(test_img_list, test_mask_list)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(\n",
    "        encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=len(class_list),                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "def dice_loss(pred, target):\n",
    "    smooth = 1e-6\n",
    "    dice_per_class = torch.zeros((len(pred))).to(pred.device)\n",
    "    pred=F.softmax(pred,dim=1)\n",
    "    for i in range(len(pred)):\n",
    "        pred_class = pred[i,...]\n",
    "        target_class = target[i, ...]\n",
    "        \n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "        dice_per_class[i] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return 1-dice_per_class.mean()\n",
    "\n",
    "model.load_state_dict(torch.load('../../model/areaSeg/breast/ST_callback.pt'))\n",
    "# summary(model,(batch_size,3,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "model_path='../../model/areaSeg/breast/'\n",
    "create_dir(model_path)\n",
    "MIN_loss=5000\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = dice_loss(predict, y) # cost 구함\n",
    "        acc=1-cost.item()\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        y = y.to('cpu')\n",
    "\n",
    "        x=x.to('cpu')\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {1-running_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count))\n",
    "#test\n",
    "    val=tqdm(test_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = dice_loss(predict, y) # cost 구함\n",
    "            acc=1-cost.item()\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            y = y.to('cpu')\n",
    "            x=x.to('cpu')\n",
    "            val.set_description(f\"test epoch: {epoch+1}/{1000} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {1-val_running_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count))\n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), f'{model_path}ST_callback.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "        \n",
    "    if epoch%50==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.title('loss_graph')\n",
    "plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "plt.plot(np.arange(epoch+1),val_loss_list,label='test_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)  \n",
    "plt.title('acc_graph')\n",
    "plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "plt.plot(np.arange(epoch+1),val_acc_list,label='test_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('batch size= 2')\n",
    "print('image size= 1024,1024')\n",
    "print('learning rate= 2e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.title('loss_graph')\n",
    "plt.plot(np.arange(epoch),train_loss_list,label='train_loss')\n",
    "plt.plot(np.arange(epoch),val_loss_list,label='test_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)  \n",
    "plt.title('acc_graph')\n",
    "plt.plot(np.arange(epoch),train_acc_list,label='train_acc')\n",
    "plt.plot(np.arange(epoch),val_acc_list,label='test_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0, 1]) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('batch size= 2')\n",
    "print('image size= 1024,1024')\n",
    "print('learning rate= 2e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    0: (255, 255, 255),          # Background - White\n",
    "    1: (0, 255, 0),        # NT_stroma - Green\n",
    "    2: (0, 0, 255),        # NT_epithelial - Blue\n",
    "    3: (255, 255, 0),      # NT_immune - Yellow\n",
    "    4: (255, 0, 0),        # Tumor - Red\n",
    "    5: (255, 165, 0),      # TP_invasive - Orange\n",
    "    6: (128, 0, 128),      # TP_in_situ - Purple\n",
    "}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 테스트 데이터에서 첫 번째 배치 가져오기\n",
    "    test_iter = iter(test_dataloader)\n",
    "    x_test, y_test = next(test_iter)\n",
    "    \n",
    "    # GPU로 이동\n",
    "    x_test = x_test.to(device).float()\n",
    "    y_test = y_test.to(device).float()\n",
    "    \n",
    "    # 모델 예측\n",
    "    predict = model(x_test)\n",
    "    predict_softmax = F.softmax(predict, dim=1)\n",
    "    predict_argmax = torch.argmax(predict_softmax, dim=1)\n",
    "    \n",
    "    # CPU로 이동하여 numpy로 변환\n",
    "    x_test_np = x_test.cpu().numpy()\n",
    "    y_test_np = y_test.cpu().numpy() \n",
    "    predict_np = predict_argmax.cpu().numpy()\n",
    "    \n",
    "    # 배치에서 첫 번째 이미지만 시각화\n",
    "    batch_idx = 0\n",
    "    \n",
    "    # 원본 이미지 준비 (CHW -> HWC)\n",
    "    original_img = np.transpose(x_test_np[batch_idx], (1, 2, 0))\n",
    "    \n",
    "    # Ground Truth 마스크를 RGB로 변환\n",
    "    gt_mask_rgb = np.zeros((img_size, img_size, 3), dtype=np.uint8)\n",
    "    gt_argmax = np.argmax(y_test_np[batch_idx], axis=0)\n",
    "    for class_idx, color in color_map.items():\n",
    "        gt_mask_rgb[gt_argmax == class_idx] = color\n",
    "    \n",
    "    # Prediction 마스크를 RGB로 변환\n",
    "    pred_mask_rgb = np.zeros((img_size, img_size, 3), dtype=np.uint8)\n",
    "    for class_idx, color in color_map.items():\n",
    "        pred_mask_rgb[predict_np[batch_idx] == class_idx] = color\n",
    "    \n",
    "    # 오버랩 결과 생성 (원본 이미지 + 예측 마스크)\n",
    "    alpha = 0.4  # 투명도\n",
    "    overlay_img = (original_img * 255).astype(np.uint8)  # 0-1 범위를 0-255로 변환\n",
    "    \n",
    "    # 예측 마스크를 오버랩 (배경 제외)\n",
    "    for class_idx, color in color_map.items():\n",
    "        if class_idx == 0:  # 배경은 제외\n",
    "            continue\n",
    "        mask_area = (predict_np[batch_idx] == class_idx)\n",
    "        if mask_area.any():\n",
    "            # 색상을 numpy array로 변환하고 오버레이 적용\n",
    "            color_array = np.array(color, dtype=np.uint8)\n",
    "            overlay_img[mask_area] = (1 - alpha) * overlay_img[mask_area] + alpha * color_array\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    axes[0, 0].imshow(original_img)\n",
    "    axes[0, 0].set_title('Original Image', fontsize=14)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Ground Truth\n",
    "    axes[0, 1].imshow(gt_mask_rgb)\n",
    "    axes[0, 1].set_title('Ground Truth', fontsize=14)\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[1, 0].imshow(pred_mask_rgb)\n",
    "    axes[1, 0].set_title('Prediction', fontsize=14)\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Overlay (원본 + 예측)\n",
    "    axes[1, 1].imshow(overlay_img.astype(np.uint8))\n",
    "    axes[1, 1].set_title('Original + Prediction Overlay', fontsize=14)\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 클래스별 색상 범례 표시\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    for i, (class_idx, color) in enumerate(color_map.items()):\n",
    "        plt.barh(0, 1, left=i, color=np.array(color)/255.0, edgecolor='black')\n",
    "        plt.text(i+0.5, 0, class_list[class_idx], ha='center', va='center', \n",
    "                rotation=45, fontsize=10)\n",
    "    \n",
    "    plt.xlim(0, len(color_map))\n",
    "    plt.ylim(-0.5, 0.5)\n",
    "    plt.title('Class Color Map', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03831329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 성능 평가 (논문용)\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# seaborn import 수정\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except:\n",
    "    print(\"seaborn 사용 불가, matplotlib만 사용합니다.\")\n",
    "    sns = None\n",
    "\n",
    "def calculate_dice_coefficient(pred, target, smooth=1e-6):\n",
    "    \"\"\"클래스별 Dice coefficient 계산\"\"\"\n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "    return dice\n",
    "\n",
    "def calculate_iou(pred, target, smooth=1e-6):\n",
    "    \"\"\"클래스별 IoU 계산\"\"\"\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "def calculate_95_ci(data):\n",
    "    \"\"\"95% 신뢰구간 계산\"\"\"\n",
    "    mean = np.mean(data)\n",
    "    se = stats.sem(data)  # Standard Error\n",
    "    ci = stats.t.interval(0.95, len(data)-1, loc=mean, scale=se)\n",
    "    return mean, ci\n",
    "\n",
    "# 테스트셋 전체 평가\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "all_dice_scores = {i: [] for i in range(len(class_list))}\n",
    "all_iou_scores = {i: [] for i in range(len(class_list))}\n",
    "pixel_accuracies = []\n",
    "\n",
    "print(\"테스트셋 평가 중...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx_eval, (x_test_eval, y_test_eval) in enumerate(tqdm(test_dataloader)):\n",
    "        # GPU로 이동\n",
    "        x_test_eval = x_test_eval.to(device).float()\n",
    "        y_test_eval = y_test_eval.to(device).float()\n",
    "        \n",
    "        # 모델 예측\n",
    "        predict_eval = model(x_test_eval)\n",
    "        predict_softmax_eval = F.softmax(predict_eval, dim=1)\n",
    "        predict_argmax_eval = torch.argmax(predict_softmax_eval, dim=1)\n",
    "        \n",
    "        # CPU로 이동하여 numpy로 변환\n",
    "        y_test_eval_np = y_test_eval.cpu().numpy() \n",
    "        predict_eval_np = predict_argmax_eval.cpu().numpy()\n",
    "        \n",
    "        # 각 이미지에 대해 처리\n",
    "        for i in range(predict_eval_np.shape[0]):\n",
    "            y_true = np.argmax(y_test_eval_np[i], axis=0)  # (H, W)\n",
    "            y_pred = predict_eval_np[i]  # (H, W)\n",
    "            \n",
    "            # 전체 예측 저장 (혼동 행렬용)\n",
    "            all_predictions.extend(y_pred.flatten())\n",
    "            all_targets.extend(y_true.flatten())\n",
    "            \n",
    "            # Pixel Accuracy\n",
    "            pixel_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "            pixel_accuracies.append(pixel_acc)\n",
    "            \n",
    "            # 클래스별 Dice와 IoU 계산\n",
    "            for class_idx in range(len(class_list)):\n",
    "                y_true_class = (y_true == class_idx).astype(np.float32)\n",
    "                y_pred_class = (y_pred == class_idx).astype(np.float32)\n",
    "                \n",
    "                dice = calculate_dice_coefficient(y_pred_class, y_true_class)\n",
    "                iou = calculate_iou(y_pred_class, y_true_class)\n",
    "                \n",
    "                all_dice_scores[class_idx].append(dice)\n",
    "                all_iou_scores[class_idx].append(iou)\n",
    "\n",
    "# 결과 정리 및 출력\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"테스트셋 성능 평가 결과 (Test Set Performance Evaluation)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 전체 Pixel Accuracy\n",
    "pixel_acc_mean, pixel_acc_ci = calculate_95_ci(pixel_accuracies)\n",
    "print(f\"\\n1. Pixel Accuracy:\")\n",
    "print(f\"   Mean ± Std: {pixel_acc_mean:.4f} ± {np.std(pixel_accuracies):.4f}\")\n",
    "print(f\"   95% CI: [{pixel_acc_ci[0]:.4f}, {pixel_acc_ci[1]:.4f}]\")\n",
    "print(f\"   Min: {np.min(pixel_accuracies):.4f}, Max: {np.max(pixel_accuracies):.4f}\")\n",
    "\n",
    "# 2. 클래스별 Dice Score\n",
    "print(f\"\\n2. Dice Score per Class:\")\n",
    "print(f\"{'Class':<25} {'Mean':<8} {'Std':<8} {'95% CI':<20} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "dice_means = []\n",
    "for class_idx in range(len(class_list)):\n",
    "    dice_mean, dice_ci = calculate_95_ci(all_dice_scores[class_idx])\n",
    "    dice_std = np.std(all_dice_scores[class_idx])\n",
    "    dice_min = np.min(all_dice_scores[class_idx])\n",
    "    dice_max = np.max(all_dice_scores[class_idx])\n",
    "    dice_means.append(dice_mean)\n",
    "    \n",
    "    print(f\"{class_list[class_idx]:<25} {dice_mean:<8.4f} {dice_std:<8.4f} [{dice_ci[0]:.4f}, {dice_ci[1]:.4f}] {dice_min:<8.4f} {dice_max:<8.4f}\")\n",
    "\n",
    "# 전체 평균 Dice Score\n",
    "overall_dice_mean = np.mean(dice_means)\n",
    "overall_dice_std = np.std(dice_means)\n",
    "print(f\"\\nOverall Mean Dice Score: {overall_dice_mean:.4f} ± {overall_dice_std:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
